#模型比较

KNN
核心思想
给定一个训练数据集，对新的输入实例，在训练集中找到与该实例最相近的k个实例，这k个实例的多数属于某个分类，就把该输入分为这个类。
常用实现：kd树

朴素贝叶斯
对于给定训练数据集，首先基于特征条件独立假设学习输入/输出的联合概率分布；然后基于此模型，对给定输入x，利用贝叶斯定理求出后验概率最大的输出y。

决策树
在分类问题中，表示基于特征对实例进行分类的过程，它可以认为是if-then规则的集合。
常用实现：CART，ID3， C4.5

逻辑回归


支持向量机
支持向量机模型是定义在特征空间上的间隔最大的线性分类器，间隔最大使得它有别于感知机；支持向量机还包括和技巧，这使支持向量机可以升级为非线性分类器。


EM
EM是一种迭代算法，用于含有隐变量的概率模型参数的极大似然估计，或极大后验概率估计。

隐马尔科夫模型
用来描述一个含有隐含未知参数的马尔可夫过程。其难点是从可观察的参数中确定该过程的隐含参数。然后利用这些参数来作进一步的分析。[简明的隐马尔科夫链介绍](http://www.cnblogs.com/skyme/p/4651331.html)

集成学习（使用同一种分类模型）

 - bagging：基本模型为Tree，用于非线性模型
 - boosting： adaboost（效率）， realboost（精度）

模型融合
